title/intro
Ok, so there are 3 parts to this talk - // firstly, I'll discuss gravity and why it's interesting to simulate. // Second, I'll discuss how I simulate systems, and // finally I'll discuss what I'm simulating - namely globular clusters.

basics
At it’s simplest level, we’re simulating the force of gravity. Why bother? Well, it’s interesting. // With 2 bodies we know exactly what will happen, it’s a solved problem. We know that particles will travel in conic sections (mostly ellipses in bound systems) around a common centre of mass.

more bodies
There is no analytical solution for more than 2 bodies, because their motion is often chaotic. // We have to manually calculate the forces, move the particles along due to that force then repeat at the new positions. The simplest way of doing this would be to assume that over our timestep, we've got a constant force. Then we work out the velocity change due to this force and find how the position changes. There's one small problem. // Gravity follows an r-squared force law so the force can often change quickly. Suppose the object is moving towards a heavy object. As it gets closer, the integration will always underestimate the force acting on the object, so errors will build up. // But, by leapfrog integration we avoid this by shifting the velocity calculation by half a timestep, so effectively the force is the midpoint of the calculation instead of the start. This decreases the error, because it's a 2nd order accuracy method - but crucially, it only has the same number of steps as the 1st order method - that makes it useful for us.

Python
I used python to write a program that takes N objects with masses, positions and velocities and evolves them over time. This is simple enough in theory - find the force on every particle from every other particle then integrate for their new positions - but it takes a long time. // Every object causes a force on every other particle, so every single particle pair must have their force calculated. The number of calculations needed scales with the number of particles squared! The exact number is N(N+1)/2 but when describing complexity, we use 'Big O' notation which only considers the largest affecting factor - in this case N squared.
I’ve sped my implementation up by using a python module which uses just-in-time compilation, which caches compiled code to reuse and results in a speed increase of 10-100x. But... it’s still slow. // One of my considerations for the future is implementing a better algorithm for the process, such as the one described by Barnes & Hut in 1986 which divides particles into cubes in space, assuming that far-off cubes can be approximated as points at their centre of mass. This algorithm runs in approximately big-O of N log N, which is a huge speedup on N squared.

Clusters
Over the past few months I’ve been testing various systems but focusing on globular clusters. Most astronomical systems exist in virial equilibrium – this state balances kinetic and potential energy. In globular clusters, this balance can be maintained by either random motions (known as pressure-supported systems) or, more often seen in large systems – e.g. galaxies – rotational motion. //
For large numbers of particles, upwards of ~1 million, particles are often spread out such that they do not interact much. This means they can be approximated as "collision-less", and methods other than direct N-body computation can be used. These include particle mesh methods. // However, for smaller systems such as clusters of stars, close encounters occur more often and can break equilibrium. They do this by falling into a potential well then generating kinetic energy as they escape, causing instability in the system, resulting in either collapse or unchecked expansion. This system, which I simulated, shows a high density system which has a strong initial collapse followed by a large expansion as gravitational potential energy was converted to kinetic energy. Towards the end of the simulation, we observe a small core of particles being retained, whilst some particles slowly escape to effectively infinity.

Encounters
Why did the previous diagram ‘explode’? // The potential well becomes steep at small distances, so a timestep and softening which functions perfectly for large separations can fail entirely at the smaller scale. How often do these encounters occur? Well, we can say that the region of close encounters is where kinetic and gravitational potential are similarly scaled. This gives us an encounter radius dependent on v squared – that is, fast particles can go closer together before being affected. // If we know the particle density, we can find a time scale between encounters by counting how many particles travel through the cylinder of the encounter radius. Note that we’ve got a velocity cubed dependence – suggesting that it’s very hard to ‘trap’ high velocity objects. This reasoning can also be expanded to an entire system.

Crossing and Relaxation
Relaxation time is the time a system takes to return to equilibrium when it's been disturbed. For example, high velocity water molecules evaporate from a puddle, leaving only the lower velocity particles. These then 'relax' back into equilibrium at a slightly lower temperature. A similar process occurs in star clusters due to all the interactions between particles. // Strong encounters work towards relaxation time, but there are many more weak encounters in a time period. Without going through the derivation which is somewhat involved, we can come up with an approximate figure by removing various coefficients close to unity. The NR/v comes from strong encounters, where N is the number of particles in the system and R is its radius. The other factor comes from weak encounters, and I've found a few values for this, ranging from 6 to 12 because it relies on various assumptions. // Note that if N is large, relaxation time becomes many times larger than the crossing time. This implies that individual encounters do not affect the overall system much. However, when N is smaller - say only a few hundred, or hundred thousand, for example - the effects of individual encounters can dominate and be important to the lifetime of the system. // You can see that here, as in a simulation with only 100 particles, the collapse occurs then equilibrium is roughly reached in only a few thousand timesteps. This is the first focus of my research: to study the accuracy of the equation here, specifically testing whether the underlying assumptions are valid, and if so do they break down in certain situations.

Conclusion
So, thank you very much for listening. To recap, we know // that gravity is interesting - but needs numerical simulations to see what happens. // The code works but is slow, so small N systems can be tested. // For these small N's, we know that strong and weak encounters determine the relaxation time, but how exactly are they connected?
//
Any Questions?
